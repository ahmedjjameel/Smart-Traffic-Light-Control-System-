# Smart-Traffic-Light-Control-System-

![image](https://github.com/ahmedjjameel/Smart-Traffic-Light-Control-System-/assets/81799459/4379ea74-c175-431d-82f7-7cec25b08a31)


# Abstract: 
Traffic congestion has become a serious issue due to the growing number of vehicles everywhere. Traffic light control system is widely used to control the flow of road junction. Currently, most of the traffic light system used pre-time and count down timers to control traffic flow. Due to the fixed-time setting, often the system unable to handle unexpected heavy traffic flows and cause traffic jam.  Thus, there is a need of adaptive traffic signals which are able to do real time monitoring to control traffic light signal based on traffic density. In this proposal, an adaptive traffic light control system that uses Artificial Intelligence (AI) and image processing and image matching techniques in controlling the traffic in an effective manner by taking images of each lane at a junction. The density of traffic in the images at each junction are compared and more time will be allocated for the vehicles on the densest road to pass compared to other less dense road.


1. Introduction 
Traffic light play an important role in controlling and regulating traffic on a daily basis. Currently, there are several types of traffic lights used such as pre-timed traffic light with the timing for each signal is determined based on traffic volume and traffic patterns in each particular area. Another type of traffic light is a countdown timer where a two-digit time indicator located on top of the pole above the traffic signal which is used to help the motorists to be conscious of the time left on the green phase as well as to have a better judgment of the traffic flow. Heavy traffic congestion has noticeably increased in major cities and this usually occurred at the main junctions especially during peak hours.  
The common types of traffic light is a pre-timed traffic light with the signal timing cycle length usually falling between 45 and 90 seconds. Since they are pre-programmed to wait for a fixed duration of time after every change in signal, they are independent of the traffic on the roads and remain constant throughout their operation. Therefore, even if the traffic density in a particular lane is the least, users are still required to wait for their turn to receive the green signal for a long period of time and when it is their turn to go, it makes other lanes wait for even longer durations.  
There is a suggestion to improve traffic light system by using PIC microcontroller (e.g., Arduino, Raspberry Pi)  as intelligent traffic signal system embedded with infrared sensor to measure the traffic density. The drawback of this system is that the infrared sensors only work for fewer distances, thus it may give inaccurate data when there is a heavy traffic congestion. Most of the countries in the world have road prevention maintenance strategy to provide immediately repaired on road distress. The conventional human based inspection method is too subjective and inaccurate. 
Hence, we propose an adaptive traffic light control system by detecting the density of road by AI and image processing techniques. The system detects the density of road and determine the time allocation for each lane. Designing and implementing a smart traffic light control system using AI and image processing techniques can significantly improve traffic management efficiency.

2. Proposed System Overview 
Our proposed system takes an image from the CCTV cameras at traffic junctions as input for realtime traffic density calculation using image processing and object detection. This system can be broken down into 3 modules: Vehicle Detection module, Signal Switching Algorithm, and Simulation module. As shown in the figure below, this image is passed on to the vehicle detection algorithm, which uses YOLO (You only look once). The number of vehicles of each class, such as car, bike, bus, and truck, is detected, which is to calculate the density of traffic. The signal switching algorithm uses this density, among some other factors, to set the green signal timer for each lane. The red signal times are updated accordingly. The green signal time is restricted to a maximum and minimum value in order to avoid starvation of a particular lane. A simulation is also developed to demonstrate the system’s effectiveness and compare it with the existing static system. 

3. Vehicle Detection Module 
The proposed system uses YOLO for vehicle detection, which provides the desired accuracy and processing time. A custom YOLO model will be trained for vehicle detection, which can detect vehicles of different classes like cars, bikes, heavy vehicles (buses and trucks), and rickshaws.
	The dataset for training the model is prepared by scraping images from google and labelling them manually using LabelIMG, a graphical image annotation tool. Then the model is trained using the pre-trained weights downloaded from the YOLO website. The configuration of the .cfg file used for training is changed in accordance with the specifications of our model. The number of output neurons in the last layer is set equal to the number of classes the model is supposed to detect by changing the 'classes' variable. In our system, this is 4 viz. Car, Bike, Bus/Truck, and Rickshaw. The number of filters also needs to be changed by the formula 5*(5+number of classes), i.e., 45 in our case.  
	After making these configuration changes, the model is trained until the loss is significantly less and no longer seemed to reduce. This marked the end of the training, and the weights are now updated according to our requirements.
	These weights are then imported in code and used for vehicle detection with the help of OpenCV library. A threshold is set as the minimum confidence required for successful detection. After the model is loaded and an image is fed to the model, it gives the result in a JSON format i.e., in the form of key-value pairs, in which labels are keys, and their confidence and coordinates are values. Again, OpenCV can be used to draw the bounding boxes on the images from the labels and coordinates received.  

4. Signal Switching Algorithm 
The Signal Switching Algorithm sets the green signal timer according to traffic density returned by the vehicle detection module, and updates the red signal timers of other signals accordingly. It also switches between the signals cyclically according to the timers.  
The algorithm takes the information about the vehicles that are detected from the detection module, as explained in the previous section, as input. This is in JSON format, with the label of the object detected as the key and the confidence and coordinates as the values. This input is then parsed to calculate the total number of vehicles of each class. After this, the green signal time for the signal is calculated and assigned to it, and the red signal times of other signals are adjusted accordingly. The algorithm can be scaled up or down to any number of signals at an intersection.   
 
The following factors are considered while developing the algorithm:  
	The processing time of the algorithm to calculate traffic density and then the green light duration – this decides at what time the image needs to be acquired  
	Number of lanes  
	Total count of vehicles of each class like cars, trucks, motorcycles, etc.  
	Traffic density calculated using the above factors  
	Time added due to lag each vehicle suffers during start-up and the non-linear increase in lag suffered by the vehicles which are at the back 
	The average speed of each class of vehicle when the green light starts i.e. the average time required to cross the signal by each class of vehicle  
	The minimum and maximum time limit for the green light duration - to prevent starvation  
 
5. Working of the algorithm 
When the algorithm is first run, the default time is set for the first signal of the first cycle and the times for all other signals of the first cycle and all signals of the subsequent cycles are set by the algorithm. A separate thread is started which handles the detection of vehicles for each direction and the main thread handles the timer of the current signal. When the green light timer of the current signal (or the red light timer of the next green signal) reaches 0 seconds, the detection threads take the snapshot of the next direction. The result is then parsed and the timer of the next green signal is set. All this happens in the background while the main thread is counting down the timer of the current green signal. This allows the assignment of the timer to be seamless and hence prevents any lag. Once the green timer of the current signal becomes zero, the next signal becomes green for the amount of time set by the algorithm.   
The image is captured when the time of the signal that is to turn green next is 0 seconds. This gives the system a total of 5 seconds (equal to value of yellow signal timer) to process the image, to detect the number of vehicles of each class present in the image, calculate the green signal time, and accordingly set the times of this signal as well as the red signal time of the next signal. To find the optimum green signal time based on the number of vehicles of each class at a signal, the average speeds of vehicles at startup and their acceleration times are used, from which an estimate of the average time each class of vehicle takes to cross an intersection is found. The green signal time is then calculated using the formula below.   
GST=(∑_vehiclClass▒(〖NoOfVehicles〗_vehicleClass*〖AverageTime〗_vehicleClass ) )/((NoOfLanes+1) )                    (1)
where:  
	GST is green signal time  
	noOfVehiclesOfClass is the number of vehicles of each class of vehicle at the signal as detected by the vehicle detection module,   
	averageTimeOfClass is the average time the vehicles of that class take to cross an intersection, and  
	noOfLanes is the number of lanes at the intersection.  
The average time each class of vehicle takes to cross an intersection can be set according to the location, i.e., region-wise, city-wise, locality-wise, or even intersection-wise based on the characteristics of the intersection, to make traffic management more effective. Data from the respective transport authorities can be analyzed for this.    
The signals switch in a cyclic fashion and not according to the densest direction first. This is in accordance with the current system where the signals turn green one after the other in a fixed pattern and does not need the people to alter their ways or cause any confusion. The order of signals is also the same as the current system, and the yellow signals have been accounted for as well.   
 
Order of signals: Red → Green → Yellow → Red

6. Simulation Module 
A simulation is developed from scratch using pygame to simulate real-life traffic. It assists in visualizing the system and comparing it with the existing static system. It contains a 4-way intersection with 4 traffic signals. Each signal has a timer on top of it, which shows the time remaining for the signal to switch from green to yellow, yellow to red, or red to green. Each signal also has the number of vehicles that have crossed the intersection displayed beside it. Vehicles such as cars, bikes, buses, trucks, and rickshaws come in from all directions. In order to make the simulation more realistic, some of the vehicles in the rightmost lane turn to cross the intersection. Whether a vehicle will turn or not is also set using random numbers when the vehicle is generated. It also contains a timer that displays the time elapsed since the start of the simulation. 
